{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson2 畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- Section1 解説\n",
    "  - 1.1 CNN基礎\n",
    "  - 1.2 Convolution(畳み込み)層\n",
    "  - 1.3 Pooling(プーリング)層\n",
    "  - 1.4 確認問題\n",
    "- Section2 実装①\n",
    "  - 2.1 Fasion MNISTをCNNでクラス分類\n",
    "  - 2.2 CIFAR10のデータをCNNでクラス分類\n",
    "- Section3 テクニック・発展内容\n",
    "  - 3.1 Data Augmentation\n",
    "  - 3.2 画像データの正規化\n",
    "  - 3.3 Batch Normalization\n",
    "  - 3.4 Skip Connection  (Residual Network)\n",
    "  - 3.5 学習済みネットワークの利用\n",
    "  - 3.6 学習させたモデルの保存・再利用\n",
    "  - 3.7 確認問題\n",
    "- Section4 実装②\n",
    "  - 4.1 CIFAR10のデータをCNNでクラス分類②\n",
    "- Section5 ケーススタディ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 の解答\n",
    "\n",
    "問1: ② 問2: ① 問3: ① 問4: ①"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4 実装②"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CIFAR10のデータをCNNでクラス分類②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = np.eye(10)[y_train.astype('int32').flatten()]\n",
    "\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_test = np.eye(10)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section3の学習内容も踏まえて、CIFAR10のクラス分類を行いたいと思います。\n",
    "\n",
    "まず、モデルの作成を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(120, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->120\n",
    "model.add(Dense(84, activation='relu', kernel_initializer='he_normal'))  # 120 ->84\n",
    "model.add(Dense(10, activation='softmax'))  # 84 ->10\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Section3で学習したDataAugumentationや画像データの正規化を学習に反映させてみます。\n",
    "\n",
    "kerasのImageDataGeneratorを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    # 3.2.1 Global Contrast Normalization (GCN) (Falseに設定しているのでここでは使用していない)\n",
    "    samplewise_center=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False)  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening (Falseに設定しているのでここでは使用していない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1969: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 30s 35ms/step - loss: 1.8769 - accuracy: 0.3066 - val_loss: 1.5922 - val_accuracy: 0.4093\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.6510 - accuracy: 0.3929 - val_loss: 1.4883 - val_accuracy: 0.4591\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 13s 31ms/step - loss: 1.5742 - accuracy: 0.4245 - val_loss: 1.4698 - val_accuracy: 0.4653\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.5153 - accuracy: 0.4539 - val_loss: 1.4453 - val_accuracy: 0.4824\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.4755 - accuracy: 0.4668 - val_loss: 1.3885 - val_accuracy: 0.5020\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 13s 32ms/step - loss: 1.4355 - accuracy: 0.4829 - val_loss: 1.3466 - val_accuracy: 0.5195\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.4081 - accuracy: 0.4929 - val_loss: 1.3547 - val_accuracy: 0.5189\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.3860 - accuracy: 0.5013 - val_loss: 1.3152 - val_accuracy: 0.5344\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.3662 - accuracy: 0.5088 - val_loss: 1.2371 - val_accuracy: 0.5626\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.3470 - accuracy: 0.5178 - val_loss: 1.2347 - val_accuracy: 0.5592\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 13s 32ms/step - loss: 1.3320 - accuracy: 0.5217 - val_loss: 1.2763 - val_accuracy: 0.5506\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.3159 - accuracy: 0.5272 - val_loss: 1.2133 - val_accuracy: 0.5687\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.3026 - accuracy: 0.5322 - val_loss: 1.2107 - val_accuracy: 0.5728\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2930 - accuracy: 0.5378 - val_loss: 1.2061 - val_accuracy: 0.5740\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2821 - accuracy: 0.5405 - val_loss: 1.2083 - val_accuracy: 0.5792\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2684 - accuracy: 0.5454 - val_loss: 1.2111 - val_accuracy: 0.5740\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2566 - accuracy: 0.5496 - val_loss: 1.2026 - val_accuracy: 0.5754\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2558 - accuracy: 0.5510 - val_loss: 1.2269 - val_accuracy: 0.5741\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 13s 31ms/step - loss: 1.2400 - accuracy: 0.5573 - val_loss: 1.1654 - val_accuracy: 0.5942\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2367 - accuracy: 0.5572 - val_loss: 1.1603 - val_accuracy: 0.5897\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2271 - accuracy: 0.5626 - val_loss: 1.2041 - val_accuracy: 0.5816\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2136 - accuracy: 0.5648 - val_loss: 1.1585 - val_accuracy: 0.5892\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2126 - accuracy: 0.5666 - val_loss: 1.1269 - val_accuracy: 0.6041\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2042 - accuracy: 0.5673 - val_loss: 1.1130 - val_accuracy: 0.6029\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.2056 - accuracy: 0.5702 - val_loss: 1.0763 - val_accuracy: 0.6213\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.1986 - accuracy: 0.5722 - val_loss: 1.1099 - val_accuracy: 0.6087\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.1865 - accuracy: 0.5749 - val_loss: 1.1005 - val_accuracy: 0.6083\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 13s 31ms/step - loss: 1.1838 - accuracy: 0.5764 - val_loss: 1.1891 - val_accuracy: 0.5885\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.1879 - accuracy: 0.5791 - val_loss: 1.1170 - val_accuracy: 0.6078\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.1741 - accuracy: 0.5797 - val_loss: 1.1344 - val_accuracy: 0.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17b6e043e48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
